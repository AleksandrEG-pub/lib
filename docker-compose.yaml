name: it_one

services:
  kafka:
    image: apache/kafka:3.7.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'
      KAFKA_LISTENERS: 'CONTROLLER://:9093,PLAINTEXT://:9092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'it_one'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  seaweedfs:
    image: chrislusf/seaweedfs:4.04
    ports:
      - "10456:8333"
      - "10457:23646"
    command: "server -s3 -dir=/data"

  spark-upload:
    build:
      context: .
      dockerfile: Dockerfile.spark_app
      target: py_spark_app
    env_file:
      - path: ./env/database_docker.env
        required: true
      - path: ./env/spark.env
        required: true
      - path: ./env/s3_docker.env
        required: true
    environment:
      - DEBUG=0 # set 1 to enable remote debug on 5678 port, 0 to disable
    depends_on:
      - spark-master
      - spark-worker
    ports:
      - "5678:5678"

  spark-master:
    # 7077:7077 api
    # 10458:8080 ui
    build:
      context: .
      dockerfile: Dockerfile.spark_app
      target: spark_s3
    command: >
      sh -c "
        /opt/spark/sbin/start-master.sh;
        tail -F /opt/spark/logs/spark-spark-org.apache.spark.deploy.master*.out
      "
    ports:
      - "10458:8080"
      
  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark_app
      target: spark_s3
    depends_on:
      - spark-master
    command: >
      sh -c "
        /opt/spark/sbin/start-worker.sh spark://spark-master:7077;
        tail -F /opt/spark/logs/spark-spark-org.apache.spark.deploy.worker*.out
      "
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1G

  database-lib:
    image: postgres:17.5
    restart: unless-stopped
    ports:
      - "10452:5432"
    env_file:
      - ./env/database.env

  clickhouse:
    image: clickhouse:25.11.3.54-jammy
    restart: unless-stopped
    env_file:
      - path: ./env/clickhouse.env
        required: true
    ports:
      - "10453:8123"
      - "10454:9000"

  grafana:
    image: grafana/grafana:12.3.0-18765596677-ubuntu
    restart: unless-stopped
    env_file:
      - ./grafana/.env
    ports:
      - "10455:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - ./grafana/grafana.ini:/usr/local/etc/grafana/grafana.ini
    depends_on:
      - clickhouse
